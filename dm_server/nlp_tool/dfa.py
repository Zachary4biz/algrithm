# encoding:utf-8
# author: zac
# create-time: 2019/6/14 13:55
# usage: - python2.7 checked(âœ…)

from __future__ import print_function
import itertools
import re
from collections import deque
import json
import os
import sys
from io import open
import collections

class Node(object):
    """
    DFAä¸éœ€è¦åæŸ¥,æ‰€ä»¥æœªè®°å½•çˆ¶èŠ‚ç‚¹
    åœ¨DFAä¸­å¶å­èŠ‚ç‚¹æ ‡è®°äº†ä¸€ä¸ªè¯çš„ç»“æŸå¦‚, "porn "å’Œ"porno"ä¸­çš„" "å’Œ"o" |
      - è¿™ç§ç”¨å¶å­èŠ‚ç‚¹ç›´æ¥æ ‡è®°è¯æ±‡ç»“æŸçš„åšæ³•,ä¸å…¼å®¹ "æ—¢è¦å±è”½Aä¹Ÿè¦å±è”½AB",ä½†å…¶å®ä»ä¸šåŠ¡é€»è¾‘ä¸Šæ¥è¯´,å†™"A"å°±ä¸ç”¨"AB",å†™"AB"è¡¨ç¤ºè¦ç»†åˆ†çš„é‚£å°±ä¸éœ€è¦"A"
      - ä¾‹å¦‚: " porn "å’Œ" porn abc "ä¼šæŠŠ" porn "çš„æœ€åçš„ç©ºæ ¼åŠ ä¸Šchildren={"a":xxx}
      - å…¶å®ä¹Ÿä¸æ”¯æŒ "vocab" å’Œ "vocabulary" # ç»éªŒè¯æ˜¯æ”¯æŒçš„
    """
    def __init__(self, reason=None):
        self.children = None
        self.reason = reason # ä»…end_word==Trueæ—¶æœ‰å€¼, æ ‡è®°æŸä¸ªè¯æ˜¯ä»€ä¹ˆåŸå› è¢«æ ‡è®°ä¸ºæ•æ„Ÿè¯
        self.is_end_word = False # æ ‡è®°è¯æ¡ç»“æŸ(ä¸å†ç”¨å¶å­èŠ‚ç‚¹ä½œä¸ºç»“æŸæ ‡å¿—)

    def is_leaf_node(self):
        return self.children is None

    def children_names(self):
        return self.children.keys() if self.children is not None else None

    def add_child(self,v):
        if self.is_leaf_node():
            self.children = {v:Node()}
        elif v not in self.children:
            self.children[v] = Node()
        else:
            pass # DFAå­èŠ‚ç‚¹å·²æœ‰åˆ™ä¸æ›´æ–°


class DFATree(object):
    def __init__(self):
        self.root = Node()
        self._init_from_file = {
            "json":self._parse_json,
            "csv":self._parse_csv
        }
        self.support_file_type = self._init_from_file.keys()


    def _parse_json(self,path):
        with open(path,"r") as f:
            res = json.load(f)
        self.init_from_dict(res)
        return res

    # \tåˆ†å‰²ç†ç”±å’Œè¯,é€—å·åšè¯é—´åˆ†å‰²,å¦‚ä¸‹
    # 0\tABC,BCD,ABC EFG
    def _parse_csv(self,path):
        res = {}
        with open(path,"r") as f:
            for reason,word_list_str in [line.strip().split("\t") for line in f]:
                res.update({reason:word_list_str.split(",")})
        self.init_from_dict(res)
        return res

    def _add_word(self, word_inp, reason, sep =" "):
        word = sep+word_inp+sep
        node = self.root
        for idx, char in enumerate(word):
            node.add_child(char)
            node = node.children[char]
        node.reason = reason
        node.is_end_word = True

    def add_word_CN(self,word_inp,reason):
        self._add_word(word_inp, reason, sep="")

    def add_word_EN(self,word_inp,reason):
        self._add_word(word_inp, reason, sep=" ")

    def init_from_file(self, file_path, file_type):
        return self._init_from_file[file_type](file_path)


    def init_from_dict(self,watch_list_inp):
        for reason,word_list in watch_list_inp.items():
            for word in word_list:
                self.add_word_EN(word,reason)

    # dfa.getRes(" violence") è·å¾—å­—ç¬¦ä¸²æœ€åä¸€ä¸ªå­—æ¯"e"çš„Node
    def node_of_last_char(self,ss):
        bn = self.root
        for idx,c in enumerate(ss):
            bn = bn.children[c]
        return bn

    # æ¸…ç†å¥å­ä¸­çš„å„ç§ç¬¦å·
    @staticmethod
    def text_format(text_inp):
        emoji_regex = """|(\ud83d[\ude00-\ude4f])"""
        symbol_regex = """([~!@#$%^&*()_+-\={}|\[\]\\\\:";'<>?,./])""" # å°åœ°è¯­æˆ–è€…å…¶ä»–äºšæ´²è¯­è¨€éƒ½ä¸å±äº \w+ æ‰€ä»¥ä¸èƒ½è¿™æ ·å»é™¤ç¬¦å·
        regex = symbol_regex + emoji_regex
        clean_symobl = re.sub(regex," ",text_inp)
        clean_whitespace = re.sub("\\s+"," "," " +clean_symobl+ " ")
        return  clean_whitespace

    # ç›´æ¥è¿”å›groupbyçš„ç»“æœï¼Œå³[(1, <itertools._grouper at 0x10d4ae610>), (2, <itertools._grouper at 0x10d4ae550>)]
    # æ³¨æ„å¸¦itertools._grouperçš„å®é™…ç»“æœæ˜¯ [(1, [('a', 1), ('b', 1)]), (2, [('c', 2), ('d', 2)])]
    # éœ€è¦å–å‡º_grouperé‡Œæ¯é¡¹çš„é¦–é¡¹
    def _get_all_children_asIter(self,verbose=False):
        res_list = []
        def loop_to_show(cur_node, cur_res_list, cur_word, level=1):
            if cur_node.is_end_word:
                if not cur_node.is_leaf_node():
                    # æ˜¯end_wordå´ä¸æ˜¯leaf_nodeï¼Œè¯´æ˜æ˜¯chunkè¯ä¸­é—´é‚£ä¸ªç©ºæ ¼ï¼Œä¾‹å¦‚" cunt " å’Œ " cunt face "ï¼Œ
                    # 1. æ­¤æ—¶çš„end_wordå…ˆåŠ å…¥åˆ°ç»“æœä¸­
                    cur_res_list.append((cur_word, cur_node.reason))
                    # 2. ç»§ç»­å‘ä¸‹æŸ¥æ‰¾
                    for key_, sub_node in cur_node.children.items():
                        if verbose: print("|" * level + " " + key_ + "\t_" + cur_word)
                        loop_to_show(sub_node, cur_res_list, cur_word + key_, level + 1)
                else:
                    # æ—¢æ˜¯end_wordåˆæ˜¯leaf_nodeï¼Œå°±æ˜¯ä¸€ä¸ªæ™®é€šçš„single wordï¼Œç›´æ¥append
                    cur_res_list.append((cur_word, cur_node.reason))
                if verbose: print(cur_res_list[-1])
            else:
                for key_, sub_node in cur_node.children.items():
                    if verbose: print("|" * level + " " + key_ + "\t_" + cur_word)
                    loop_to_show(sub_node, cur_res_list, cur_word + key_, level+1)
        loop_to_show(self.root,res_list,cur_word = "")
        the_key = lambda x: x[1]
        res_asIter = itertools.groupby(sorted(res_list, key=the_key), key=the_key)
        return res_asIter

    # è§£å¼€groupbyçš„iter.grouperï¼Œå³å–å‡º_grouperé‡Œæ¯é¡¹çš„é¦–é¡¹ï¼Œå¾—åˆ°ä¾‹å¦‚ï¼š[(1, ['a', 'b']), (2, ['c', 'd'])]
    def get_all_children_asList(self,verbose=False):
        res_asIter = self._get_all_children_asIter(verbose)
        res_asDict = dict([(k, map(lambda x: x[0][1:-1], g)) for k, g in res_asIter])
        return res_asDict

    # do_fromatæ§åˆ¶æ˜¯å¦è‡ªåŠ¨æ¸…ç†ç¬¦å·
    def search(self, text_inp, return_json=True, do_format=True):
        text = self.text_format(text_inp) if do_format else text_inp
        word_list = deque()
        for idx,char in enumerate(text):
            if char in self.root.children:
                j = idx
                p = self.root
                while j<len(text) and not p.is_leaf_node() and text[j] in p.children:
                    p = p.children[text[j]]
                    if p.is_end_word :
                        word_list.append(("".join(text[idx:j+1]),p.reason))
                        pass # è¿™é‡Œä¸ç”¨è·³è·ƒæ€§åœ°èµ‹å€¼ idx = idx+j,å› ä¸ºè¦å…¼å®¹ç±»ä¼¼ä¸­æ–‡çš„è¯­ç§,ä» "æˆ‘çˆ±å¤©å®‰é—¨" ä¸­æ‰¾åˆ°"æˆ‘çˆ±"å’Œ"çˆ±å¤©å®‰é—¨"
                    j += 1
        word_list = [(w.strip(), r) for w,r in word_list]
        word_list = [[k[0], k[1],len(list(g))] for k,g in itertools.groupby(sorted(word_list,key=None),key=None)] # IMPORTANT æ³¨æ„groupbyå’Œsortedè¦ä½¿ç”¨ç›¸åŒçš„key,å¦åˆ™groupbyå¯èƒ½å¤±æ•ˆ
        # keyä¸æŒ‡å®šä¸ºè¯,æŒ‰wordå’Œreasonä¸€èµ·groupby;å› ä¸ºå¯èƒ½æœ‰ä¸€ä¸ªè¯å¯¹åº”å¤šä¸ªreason,å¦‚ Gaddfi å¯èƒ½åŒæ—¶æœ‰æ”¿æ²»æ•æ„Ÿå’Œå®—æ•™ä¸¤ä¸ªåŸå› 
        json_res = json.dumps([{"word":w, "reason":r, "cnt":c} for w,r,c in word_list])
        return json_res if return_json else word_list


if __name__ == '__main__':
    def test_init_from_dict(content ="   violence violences massacreadwgb violate, purpose, violate purpose, from now on massacre"):
        print(">>> AT TEST-ONE:")
        dfa = DFATree()
        watch_list = {0:["violences", "violence","violence violences", "massacre", "porn",  "kill", "violate","violate purpose"]}
        print(">>> watch_list:",watch_list)
        dfa.init_from_dict(watch_list)
        print(">>> json_res: ",dfa.search(content))
        print(">>> res -h:")
        for i in dfa.search(content,return_json=False): print(i)
        dfa.search(content)

    def test_init_from_json_file(content ="à¤¬à¤¿à¤¸à¥à¤¤à¤° à¤—à¤°à¥à¤®, à¤•à¤¾à¤®à¤•à¥à¤°à¥€à¤¡à¤¼à¤¾, à¤¸à¥‡à¤•à¥à¤¸à¥€"):
        print("\n\n>>> AT TEST-TWO:")
        dfa = DFATree()
        dfa.init_from_file(os.path.dirname(__file__)+"/TestCase/watch_list.json","json")
        print(">>> json_res: ",dfa.search(content))
        print(">>> res -h:")
        for i in dfa.search(content,return_json=False): print(i)
        dfa.search(content)

    def test_format_hindi():
        print("å°åœ°è¯­çœ‹ç€æ˜¯ä¸€ä¸ªå­—å®é™…ä¸Šæ˜¯å¤šä¸ªå­—ç¬¦:")
        hindi = "à¤¬à¤¿à¤¸à¥à¤¤à¤° à¤—à¤°à¥à¤® à¤µà¥€à¤°à¥à¤¯ à¤¹à¤¿à¤²à¤¤à¥€ à¤•à¤¾à¤°"
        print(len(hindi))
        for i in hindi:
            print(i)
            print(i in hindi)
        print(hindi)
        print(DFATree.text_format(hindi))
        print("å°åœ°è¯­çš„ re.sub: ")
        content = " à¤¬à¤¿à¤¸à¥à¤¤à¤° à¤—à¤°à¥à¤® , à¤•à¤¾à¤®à¤•à¥à¤°à¥€à¤¡à¤¼à¤¾ , à¤¸à¥‡à¤•à¥à¤¸à¥€  ~à¤¸à¥‡à¤•à¥à¤¸à¥€!à¤¸à¥‡à¤•à¥à¤¸à¥€@à¤¸à¥‡à¤•à¥à¤¸à¥€#à¤¸à¥‡à¤•à¥à¤¸à¥€$à¤¸à¥‡à¤•à¥à¤¸à¥€%à¤¸à¥‡à¤•à¥à¤¸à¥€^à¤¸à¥‡à¤•à¥à¤¸à¥€&à¤¸à¥‡à¤•à¥à¤¸à¥€*à¤¸à¥‡à¤•à¥à¤¸à¥€(à¤¸à¥‡à¤•à¥à¤¸à¥€)à¤¸à¥‡à¤•à¥à¤¸à¥€_à¤¸à¥‡à¤•à¥à¤¸à¥€+à¤¸à¥‡à¤•à¥à¤¸à¥€-à¤¸à¥‡à¤•à¥à¤¸à¥€=à¤¸à¥‡à¤•à¥à¤¸à¥€{à¤¸à¥‡à¤•à¥à¤¸à¥€}à¤¸à¥‡à¤•à¥à¤¸à¥€|à¤¸à¥‡à¤•à¥à¤¸à¥€[à¤¸à¥‡à¤•à¥à¤¸à¥€]à¤¸à¥‡à¤•à¥à¤¸à¥€\à¤¸à¥‡à¤•à¥à¤¸à¥€:à¤¸à¥‡à¤•à¥à¤¸à¥€\"à¤¸à¥‡à¤•à¥à¤¸à¥€;à¤¸à¥‡à¤•à¥à¤¸à¥€'à¤¸à¥‡à¤•à¥à¤¸à¥€<à¤¸à¥‡à¤•à¥à¤¸à¥€>à¤¸à¥‡à¤•à¥à¤¸à¥€?à¤¸à¥‡à¤•à¥à¤¸à¥€,à¤¸à¥‡à¤•à¥à¤¸à¥€.à¤¸à¥‡à¤•à¥à¤¸à¥€/à¤¸à¥‡à¤•à¥à¤¸à¥€'à¤¸à¥‡à¤•à¥à¤¸à¥€"
        print(content)
        print("re.sub2",re.sub("""[~!@#$%^&*()_+-={}|\[\]\\\\:";'<>?,./]"""," \u2717 ",content))

    def test_case_from_file():
        print("\n\n>>> AT TEST_FROM_FILE")
        dfa = DFATree()
        dfa.init_from_file(os.path.dirname(__file__)+"/TestCase/watch_list.json","json")
        with open(os.path.dirname(__file__)+"/TestCase/hindi_test_case.txt","r+") as f:
            test_case = [i.strip() for i in f.readlines()]
        for w in test_case :
            print("test-case: ",w)
            print("text_formatted: ", DFATree.text_format(w))
            print("result: ", dfa.search(w,return_json=False))

    def test_show_all_words():
        dfa = DFATree()
        dfa.init_from_file(os.path.dirname(__file__)+"/TestCase/watch_list.json","json")
        dfa_wordsDict = dfa.get_all_children_asList(verbose=False)
        print(">>> all_words:")
        for k,v in dfa_wordsDict.items():
            print(k+"\t"+", ".join(v))

    def test_on_get_all_children_asList(verbose=False):
        print("\n\n[AT TEST_ON_GET_ALL_CHILDREN_ASLIST]...")
        dfa = DFATree()
        dfa.init_from_file(os.path.dirname(__file__) + "/TestCase/watch_list.json", "json")
        dfa_wordsDict = dfa.get_all_children_asList(verbose=False)
        with open(os.path.dirname(__file__)+"/TestCase/watch_list.json","r",encoding="utf-8") as f:
            dic = json.load(f)
            for key,item in dic.items():
                item = list(set(item))
                success = sorted(item) == sorted(dfa_wordsDict[key])
                print(">>> check at [key - æ˜¯å¦å®Œå…¨ç›¸åŒ]: [{} - {}]".format(key, str(success)))
                if verbose and not success:
                    print("[file & dfa]:\t"+", ".join(set(item).intersection(dfa_wordsDict[key])))
                    print("[file - dfa]:\t"+", ".join(set(item).difference(dfa_wordsDict[key])))
                    print("[dfa - file]:\t" + ", ".join(set(dfa_wordsDict[key]).difference(item)))

    def test_check_wordChunk():
        """
        å¦‚ä¸‹æ‰€ç¤ºï¼Œå¦‚æœåŠ å…¥çš„æ˜¯chunkçš„è¯ç»„("cunt","cunt face")ï¼Œä¼šåœ¨cuntçš„è¯å°¾å‡ºç°æ ‡è®°ä¸ºis_end_word=Trueï¼Œä½†is_leaf_node()=False
        å…¶ä»–æƒ…å†µä¸‹ï¼ˆå•ä¸ªè¯ï¼‰çš„is_end_wordå’Œis_leaf_node()éƒ½æ˜¯åŒæ­¥çš„
        """
        print("\n\n[AT TEST_CHECK_WORDCHUNK]...")
        dfa = DFATree()
        dfa.add_word_EN("cunt","1")
        dfa.add_word_EN("cunt face","2")
        dfa.add_word_EN("bitch","1")
        dfa.add_word_EN("à¤¨à¤—à¥à¤¨","1")
        dfa.add_word_EN("à¤¨à¤—à¥à¤¨ à¤¤à¤¸à¥à¤µà¥€à¤°à¥‡à¤‚","1")
        for k,v in dfa.get_all_children_asList().items():
            print(k+"\t"+", ".join(v))
        def log_word(word):
            print("%s è¯å°¾ï¼ˆæœ€åä¸€ä¸ªç©ºæ ¼ï¼‰çš„childrenæœ‰å“ªäº›: " % word, dfa.node_of_last_char(" "+word+" ").children_names())
            print("%s è¯å°¾ï¼ˆæœ€åä¸€ä¸ªç©ºæ ¼ï¼‰æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹?" % word,dfa.node_of_last_char(" "+word+" ").is_leaf_node())
            print("%s è¯å°¾ï¼ˆæœ€åä¸€ä¸ªç©ºæ ¼ï¼‰æ˜¯å¦ä¸ºend_word?" % word, dfa.node_of_last_char(" "+word+" ").is_end_word)
        print(">>> chunk word:")
        log_word("cunt")
        log_word("à¤¨à¤—à¥à¤¨")
        print(">>> single word:")
        log_word("bitch")

    def test_check_single_word():
        # todo
        dfa = DFATree()
        dfa.init_from_file(os.path.dirname(__file__) + "/TestCase/watch_list.json", "json")
        # Chutiyapa
        t = dfa.root.children[" "].children["C"].children["h"].children["u"].children["t"].children["i"].children[
            "y"].children["a"].children["p"].children["a"].children[" "]


    # test_one()
    # test_init_from_json_file("à¤¬à¤¿à¤¸à¥à¤¤à¤° à¤—à¤°à¥à¤®, à¤•à¤¾à¤®à¤•à¥à¤°à¥€à¤¡à¤¼à¤¾, à¤¸à¥‡à¤•à¥à¤¸à¥€, à¤¬à¤¿à¤¸à¥à¤¤à¤° à¤—ğŸ‘Œà¤°à¥à¤®")
    # test_init_from_json_file("ass")
    # test_case_from_file()
    # test_show_all_words()
    test_on_get_all_children_asList(True)
    test_check_wordChunk()




    # inpupt = sys.argv[1]
    # print("\n\nåŸæ–‡: ",inpupt)
    # print("\nåˆ¤æ–­çš„ç»“æœ: ",dfa.search(inpupt))
    # dfa = DFATree()
    # dfa.init_from_file(os.path.dirname(__file__)+"/TestCase/watch_list.json","json")
    # for i in dfa.search(inpupt,return_json=False): print(i)

